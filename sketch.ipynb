{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e622616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9420c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "js_dataset = JSdataset('/data/js_detection/dataset',transform=transforms.Compose([\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Resize((224,224))\n",
    "                                                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64711184",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(js_dataset,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63937b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Face_detector(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3,8,kernel_size=3,padding=1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8,16,kernel_size=3,padding=1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,kernel_size=3,padding=1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64,kernel_size=3,padding=1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128,128,kernel_size=7),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(128,128)\n",
    "        self.fc2 = nn.Linear(128,2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.model(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return \"FaceDetector()\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38174c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import FaceDetector\n",
    "from dataset import JSdataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44218956",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FaceDetector()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19558381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaceDetector()\n",
      " number of parameters: 917969\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(f\" number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c234c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6614, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images,labels=next(iter(loader))\n",
    "\n",
    "\n",
    "\n",
    "images = images.to(device)\n",
    "labels = labels.type(torch.FloatTensor)\n",
    "labels = labels.to(device)\n",
    "\n",
    "loss = 0\n",
    "\n",
    "#initialize gradient\n",
    "optimizer.zero_grad()\n",
    "#forward propagation\n",
    "output = model(images)\n",
    "#calculate loss\n",
    "loss = criterion(output.squeeze(1),labels)\n",
    "#backward proopagation\n",
    "loss.backward()\n",
    "#update parameters\n",
    "optimizer.step()\n",
    "\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "485972be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cbd17470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b71dc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5262],\n",
       "        [0.5248],\n",
       "        [0.5274],\n",
       "        [0.5273],\n",
       "        [0.5277],\n",
       "        [0.5252],\n",
       "        [0.5244],\n",
       "        [0.5274],\n",
       "        [0.5260],\n",
       "        [0.5276]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77a38458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 1., 1., 1., 0., 1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bf40381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a57748d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 224, 224])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "271050c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread('/data/js_detection/dataset/pos/image00001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "836ddf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "08e347c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform =transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.Normalize((0.5244, 0.5401, 0.5397),(0.2569, 0.2638, 0.2730))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "064078a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3259de60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac23dac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
