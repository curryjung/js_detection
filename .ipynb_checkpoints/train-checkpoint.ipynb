{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f296d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import FaceDetector\n",
    "from dataset import JSdataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd89bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "epoch = 0\n",
    "learning_rate = 1e-3\n",
    "print_every = 10\n",
    "evaluate_every = 10\n",
    "out_dir = \"./out\"\n",
    "total_epoch=5\n",
    "\n",
    "\n",
    "logger = SummaryWriter(os.path.join(out_dir, 'log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1700c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1669bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, test_loader, total_epoch):\n",
    "    \n",
    "    test_images, test_labels = next(iter(test_loader))\n",
    "    test_images = test_images.to(device)\n",
    "    test_labels = test_labels.type(torch.FloatTensor)\n",
    "    test_labels = test_labels.to(device)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    it = 0\n",
    "\n",
    "    t0b = time.time()\n",
    "    for epoch in range(total_epoch):\n",
    "        for images, labels in train_loader:\n",
    "            model.train()\n",
    "            images = images.to(device)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            #initialize gradient\n",
    "            optimizer.zero_grad()\n",
    "            #forward propagation\n",
    "            output = model(images)\n",
    "            #calculate loss\n",
    "            loss = criterion(output.squeeze(1),labels)\n",
    "            #backward proopagation\n",
    "            loss.backward()\n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                prediction = get_pred(model, test_images)\n",
    "                accuracy = get_accuracy(prediction.squeeze(),test_labels)\n",
    "                print(accuracy)\n",
    "                \n",
    "            loss_dicts = {\"Train Loss\": loss}\n",
    "            logger.add_scalars(\"train_loss\",loss_dicts,it)                 \n",
    "                \n",
    "               \n",
    "\n",
    "            if print_every > 0 and (it % print_every) == 0:\n",
    "                print('[Epoch %02d] loss: %.4f it %03d, time%.3f' % (epoch,loss, it, time.time()-t0b))\n",
    "            \n",
    "            it+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14e021b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(pytorch_model,x):\n",
    "    #x = torch.Tensor(x).to(device)\n",
    "    output = pytorch_model(x)\n",
    "    output = torch.round(output)\n",
    "    output = output.detach().cpu()\n",
    "    return output    \n",
    "\n",
    "def get_accuracy(pred,label):\n",
    "    return torch.sum(pred == label).item()/len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a9cff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JSdataset('/data/js_detection/dataset',train=True,transform =transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Normalize((0.5244, 0.5401, 0.5397),(0.2569, 0.2638, 0.2730))\n",
    "]))\n",
    "\n",
    "test_dataset = JSdataset('/data/js_detection/dataset',train=False,transform =transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Normalize((0.5244, 0.5401, 0.5397),(0.2569, 0.2638, 0.2730))\n",
    "]))\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f764e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceDetector()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e80db1cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) (got TensorOptions(dtype=float, device=cuda:0, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-bf542494694b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-37ab76d4025f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_loader, test_loader, total_epoch)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-be9df13f24cb>\u001b[0m in \u001b[0;36mget_pred\u001b[0;34m(pytorch_model, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytorch_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected TensorOptions(dtype=float, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) (got TensorOptions(dtype=float, device=cuda:0, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)))"
     ]
    }
   ],
   "source": [
    "train(model=model, optimizer=optimizer, criterion=criterion, train_loader=train_loader,test_loader=test_loader,total_epoch=total_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9ac6635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb8de019",
   "metadata": {},
   "outputs": [],
   "source": [
    "images,labels = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f6af30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 3, 224, 224])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39ab99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_pred(model,images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9fe9c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = get_accuracy(output,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e312e274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5176e198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fd57e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "447de526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd78c959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ef717d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(output.squeeze() == labels).item()#/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd0ae71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = output == labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0a26396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 200])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb014315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 1, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a0ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
